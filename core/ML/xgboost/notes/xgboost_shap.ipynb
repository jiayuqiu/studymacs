{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d88c28ff81ad176c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T13:09:25.075569Z",
     "start_time": "2025-03-14T13:09:17.590738Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "25/03/15 00:11:37 WARN Utils: Your hostname, jerryasus resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/03/15 00:11:37 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/15 00:11:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/03/15 00:11:38 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal length (cm): double (nullable = true)\n",
      " |-- sepal width (cm): double (nullable = true)\n",
      " |-- petal length (cm): double (nullable = true)\n",
      " |-- petal width (cm): double (nullable = true)\n",
      " |-- label: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession.builder.appName(\"IrisXGBoost\").getOrCreate()\n",
    "\n",
    "# Load iris data\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['label'] = pd.Series(iris.target)\n",
    "\n",
    "# Assemble features into a single vector column\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[col for col in iris.feature_names],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Convert pandas DataFrame to Spark DataFrame\n",
    "spark_df = spark.createDataFrame(df)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_df, test_df = spark_df.randomSplit([0.8, 0.2], seed=42)\n",
    "train_df.printSchema()\n",
    "# train_df.select(\"label\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95085d602f23f0db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T13:09:38.362373Z",
     "start_time": "2025-03-14T13:09:28.339225Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-15 00:12:00,271 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'objective': 'multi:softprob', 'device': 'cpu', 'num_class': 3, 'kwargs': {'objective': 'multi:softprob'}, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[00:12:05] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "/home/jerry/codebase/studymacs/.venv/lib/python3.12/site-packages/xgboost/core.py:160: UserWarning: [00:12:05] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"kwargs\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2025-03-15 00:12:06,334 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-03-15 00:12:09,038 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:12:09,038 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:12:09,038 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs                               \n",
      "2025-03-15 00:12:09,165 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:12:09,168 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:12:09,171 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+-----------------+----------------+-----+-----------------+-----------------------------------------------------------+----------+----------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)|label|features         |rawPrediction                                              |prediction|probability                                                     |predict_contrib                                                                                                                                                                                                                                                               |\n",
      "+-----------------+----------------+-----------------+----------------+-----+-----------------+-----------------------------------------------------------+----------+----------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|4.9              |3.0             |1.4              |0.2             |0    |[4.9,3.0,1.4,0.2]|[2.9877431392669678,-2.521088123321533,-3.8781604766845703]|0.0       |[0.994932234287262,0.004030311480164528,0.0010374552803114057]  |[[0.0, 0.0, 3.1064515113830566, 0.0, -0.11870837211608887], [-0.9541416764259338, -0.44930654764175415, -1.9644542932510376, 0.21524153649806976, 0.6315736174583435], [-0.2419472187757492, -0.7378804683685303, -1.897713303565979, -1.629811406135559, 0.6291914582252502]]|\n",
      "|4.4              |2.9             |1.4              |0.2             |0    |[4.4,2.9,1.4,0.2]|[2.9877431392669678,-2.521088123321533,-3.8781604766845703]|0.0       |[0.994932234287262,0.004030311480164528,0.0010374552803114057]  |[[0.0, 0.0, 3.1064515113830566, 0.0, -0.11870837211608887], [-0.9541416764259338, -0.44930654764175415, -1.9644542932510376, 0.21524153649806976, 0.6315736174583435], [-0.2419472187757492, -0.7378804683685303, -1.897713303565979, -1.629811406135559, 0.6291914582252502]]|\n",
      "|5.4              |3.7             |1.5              |0.2             |0    |[5.4,3.7,1.5,0.2]|[2.9877431392669678,-2.579725503921509,-3.8781604766845703]|0.0       |[0.9951606392860413,0.0038016510661691427,0.0010376933496445417]|[[0.0, 0.0, 3.1064515113830566, 0.0, -0.11870837211608887], [-0.8577507138252258, -0.4839625954627991, -2.101142644882202, 0.23155727982521057, 0.6315736174583435], [-0.2419472187757492, -0.7378804683685303, -1.897713303565979, -1.629811406135559, 0.6291914582252502]]  |\n",
      "|4.8              |3.0             |1.4              |0.1             |0    |[4.8,3.0,1.4,0.1]|[2.9877431392669678,-2.521088123321533,-3.8781604766845703]|0.0       |[0.994932234287262,0.004030311480164528,0.0010374552803114057]  |[[0.0, 0.0, 3.1064515113830566, 0.0, -0.11870837211608887], [-0.9541416764259338, -0.44930654764175415, -1.9644542932510376, 0.21524153649806976, 0.6315736174583435], [-0.2419472187757492, -0.7378804683685303, -1.897713303565979, -1.629811406135559, 0.6291914582252502]]|\n",
      "|5.0              |3.2             |1.2              |0.2             |0    |[5.0,3.2,1.2,0.2]|[2.9877431392669678,-2.579725503921509,-3.8781604766845703]|0.0       |[0.9951606392860413,0.0038016510661691427,0.0010376933496445417]|[[0.0, 0.0, 3.1064515113830566, 0.0, -0.11870837211608887], [-0.973095178604126, -0.4850788712501526, -1.9683657884597778, 0.21524153649806976, 0.6315736174583435], [-0.2419472187757492, -0.7378804683685303, -1.897713303565979, -1.629811406135559, 0.6291914582252502]]  |\n",
      "+-----------------+----------------+-----------------+----------------+-----+-----------------+-----------------------------------------------------------+----------+----------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the Spark XGBoost classifier\n",
    "from xgboost.spark import SparkXGBClassifier\n",
    "\n",
    "# Define a subclass to add the missing __sklearn_tags__ attribute\n",
    "class FixedSparkXGBClassifier(SparkXGBClassifier):\n",
    "    __sklearn_tags__ = {}\n",
    "\n",
    "# Instantiate the XGBoost Spark classifier for multi-class classification\n",
    "xgb_classifier = SparkXGBClassifier(\n",
    "    features_col=\"features\",\n",
    "    label_col=\"label\",\n",
    "    num_class=3,\n",
    "    pred_contrib_col=\"predict_contrib\",\n",
    "    kwargs={\"objective\": \"multi:softprob\"},\n",
    ")\n",
    "\n",
    "train_dataset = assembler.transform(train_df)\n",
    "test_dataset = assembler.transform(test_df)\n",
    "\n",
    "# Train the model\n",
    "model = xgb_classifier.fit(train_dataset)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.transform(test_dataset)\n",
    "predictions.show(5, False)\n",
    "# predictions.select(\"features\", \"label\", \"prediction\", \"probabilities\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81f3286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_contrib array: [[0.0, 0.0, 3.1064515113830566, 0.0, -0.11870837211608887], [-0.9541416764259338, -0.44930654764175415, -1.9644542932510376, 0.21524153649806976, 0.6315736174583435], [-0.2419472187757492, -0.7378804683685303, -1.897713303565979, -1.629811406135559, 0.6291914582252502]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-15 00:17:55,622 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "row = predictions.first()\n",
    "predict_contrib = row[\"predict_contrib\"]\n",
    "print(\"predict_contrib array:\", predict_contrib)\n",
    "\n",
    "# # Get the number of features from one row in test_dataset\n",
    "# features_vector = test_dataset.select(\"features\").first()[\"features\"]\n",
    "# num_features = len(features_vector)\n",
    "# print(\"Number of features:\", num_features)\n",
    "\n",
    "# # Each block consists of (number of features + bias term)\n",
    "# block_length = num_features + 1\n",
    "# print(\"Per-class block length (features + bias):\", block_length)\n",
    "\n",
    "# # We set the number of classes to 3\n",
    "# num_classes = 3\n",
    "\n",
    "# # Validate the total length of predict_contrib array\n",
    "# expected_length = num_classes * block_length\n",
    "# print(\"Expected total length:\", expected_length)\n",
    "# print(\"Actual total length:\", len(predict_contrib))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a18e70",
   "metadata": {},
   "source": [
    "Copilot advised that:\n",
    "\n",
    "```\n",
    "The idea behind using the margin here comes from how SHAP values work. In XGBoost, when you use the \"pred_contrib\" output, the contributions are additive. This means that for each class, the sum of the feature contributions plus the bias equals the margin, which is the raw score (logit) before applying any normalization (like softmax). In multi-class classification:\n",
    "\n",
    "Each class gets its own margin.\n",
    "The final prediction is the class with the highest margin.\n",
    "By summing the contributions in each block, you get the margin for that class.\n",
    "If the first array (block) corresponds to class 0, then for samples predicted as class 0, the sum (margin) of the first block should be the highest among the three.\n",
    "Thus, checking the summation (margin) is a way to validate that the block order in predict_contrib aligns with the class predictions.\n",
    "```\n",
    "\n",
    "TODO: Learn more about margin and SHAP value math theroy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ecf344d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-15 00:24:34,385 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:34,401 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:34,483 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:34,507 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:34,514 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:34,515 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:37,232 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:37,233 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:37,234 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:37,237 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:37,400 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:37,401 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:37,405 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:37,430 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:37,434 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:37,483 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:37,491 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:37,497 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:37,621 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:37,847 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:37,860 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:37,876 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:37,891 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:37,970 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:38,009 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:40,531 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:40,540 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:40,547 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:40,558 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:40,579 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:40,583 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:40,588 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:40,608 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:40,610 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:40,610 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:40,637 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:40,646 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:40,676 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:40,681 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:40,694 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:40,699 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:40,713 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:40,720 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:40,732 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:40,738 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:40,860 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0:\n",
      "  Class 0 margin: -2.5659544467926025\n",
      "  Class 1 margin: 3.484293833374977\n",
      "  Class 2 margin: -1.4969568401575089\n",
      "  Predicted class: 1.0\n",
      "  -> For non-zero predictions, inspect margins accordingly.\n",
      "---------------------------------------------------\n",
      "Row 1:\n",
      "  Class 0 margin: -2.5659544467926025\n",
      "  Class 1 margin: 3.4083408564329147\n",
      "  Class 2 margin: -1.4969568401575089\n",
      "  Predicted class: 1.0\n",
      "  -> For non-zero predictions, inspect margins accordingly.\n",
      "---------------------------------------------------\n",
      "Row 2:\n",
      "  Class 0 margin: -2.5659544467926025\n",
      "  Class 1 margin: 3.4083408564329147\n",
      "  Class 2 margin: -1.4969568401575089\n",
      "  Predicted class: 1.0\n",
      "  -> For non-zero predictions, inspect margins accordingly.\n",
      "---------------------------------------------------\n",
      "Row 3:\n",
      "  Class 0 margin: -2.5659544467926025\n",
      "  Class 1 margin: 1.7605621814727783\n",
      "  Class 2 margin: -3.482727751135826\n",
      "  Predicted class: 1.0\n",
      "  -> For non-zero predictions, inspect margins accordingly.\n",
      "---------------------------------------------------\n",
      "Row 4:\n",
      "  Class 0 margin: -2.5659544467926025\n",
      "  Class 1 margin: 3.134815663099289\n",
      "  Class 2 margin: -2.8776609152555466\n",
      "  Predicted class: 1.0\n",
      "  -> For non-zero predictions, inspect margins accordingly.\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-15 00:24:41,002 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "2025-03-15 00:24:41,027 INFO XGBoost-PySpark: predict_udf Do the inference on the CPUs\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def get_class_contributions(predict_contrib, num_classes):\n",
    "    # Divide the flat predict_contrib list into num_classes blocks\n",
    "    block_size = len(predict_contrib) // num_classes\n",
    "    return [predict_contrib[i * block_size : (i + 1) * block_size] for i in range(num_classes)]\n",
    "\n",
    "def sum_block(block):\n",
    "    total = 0\n",
    "    for item in block:\n",
    "        if isinstance(item, list):\n",
    "            total += sum(item)\n",
    "        else:\n",
    "            total += item\n",
    "    return total\n",
    "\n",
    "num_classes = 3  # as set in your classifier\n",
    "\n",
    "# Extract and print contribution block sums for a few predictions\n",
    "few_rows = predictions.filter(predictions.prediction==1).limit(5).collect()\n",
    "for idx, row in enumerate(few_rows):\n",
    "    pc = row[\"predict_contrib\"]\n",
    "    blocks = get_class_contributions(pc, num_classes)\n",
    "    # Calculate margin (sum of contributions including bias) for each class using the helper function\n",
    "    margins = [sum_block(block) for block in blocks]\n",
    "    predicted = row[\"prediction\"]\n",
    "    print(f\"Row {idx}:\")\n",
    "    print(f\"  Class 0 margin: {margins[0]}\")\n",
    "    print(f\"  Class 1 margin: {margins[1]}\")\n",
    "    print(f\"  Class 2 margin: {margins[2]}\")\n",
    "    print(f\"  Predicted class: {predicted}\")\n",
    "    if predicted == 0:\n",
    "        if margins[0] >= margins[1] and margins[0] >= margins[2]:\n",
    "            print(\"  -> First array (class 0) has the highest margin. Validation OK.\")\n",
    "        else:\n",
    "            print(\"  -> Unexpected: First array margin is not highest!\")\n",
    "    else:\n",
    "        print(\"  -> For non-zero predictions, inspect margins accordingly.\")\n",
    "    print(\"---------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
