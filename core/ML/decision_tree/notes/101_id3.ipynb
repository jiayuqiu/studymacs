{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 决策树ID3学习笔记"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 一、决策树简介\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 二、流程\n",
    "\n",
    "![伪代码](../imgs/决策树基本流程.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 三、划分选择\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;随着划分过分不断进行，决策树的分支结点所包含的样本尽可能属于同一类别，即每个结点的\"纯度\"越来越高（都属于同一类型）。\n",
    "\n",
    "### 3.1 ID3方法\n",
    "\n",
    "### 3.1.1 信息增益\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;信息熵是度量样本集合纯度的一种指标。假设，样本D有K种分类，其中第k中分类的概率为 $p_{k}$ ，那么样本D的信息熵定义为\n",
    "\n",
    "$$ Ent(D) = -\\sum_{k=1}^{K} p_{k}\\log_{2} p_{k} $$\n",
    "\n",
    "其中 $ Ent(D) $ 越小，那么样本D的纯度越高（信息熵越大，那么存在的信息就越多，可以理解为样本D中可分类的空间就越大）。\n",
    "\n",
    "假设：离散属性a有 $ V $ 个可能值 $ \\{ a^{1}, a^{2}, ..., a^{V}\\} $ ，那么其中第 $ v $ 个包含的样本为 $ D^{v} $ ，可得 $ D^{v} $ 的信息熵为 $ Ent(D^{v}) $。\n",
    "\n",
    "在考虑，不同分支下，数据量的不同，赋予分支数据量权重 $ |D^{v}| / |D| $ ，那么对样本D进行a划分的信息增益为：\n",
    "\n",
    "$$ Gain(D, a) = Ent(D) - \\sum_{v=1}^{V} \\frac{|D^{v}|}{|D|} Ent(D^{v}). $$\n",
    "\n",
    "一般地，若 $ Gain(D, a) $ 信息增益越大，那么以 $ a $ 来进行划分的纯度提升越大。\n",
    "\n",
    "### 3.1.2 计算步骤\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;假设：数据集如下图所示\n",
    "\n",
    "![3.1.2数据集](../imgs/西瓜数据集2.png)\n",
    "\n",
    "1. 首先，样本对应的信息熵，其中正例8例、反例9例，总共17例。$ Ent(D) = -\\sum_{k=1}^{2} p_{k}\\log_{2} p_{k}\\ = - (\\frac{8}{17} \\log_{2} \\frac{8}{17} + \\frac{9}{17} \\log_{2} \\frac{9}{17}) = 0.998 $\n",
    "\n",
    "2. 若以色泽为例，进行划分，色泽包括 { '青绿', '乌黑', '浅白'}，那么需要计算三个信息熵，最终可得信息增益为0.109.\n",
    "3. 分别计算其他属性的划分，对应的信息增益，最终纹理属性对应的 信息增益最大 为 0.381。\n",
    "4. 以纹理作为划分，得到3个新样本集，再对3个新样本集分别重复1-3步操作。\n",
    "5. 直至无法划分出新的新样本集，算法结束。\n",
    "\n",
    "### 3.1.3 缺点总结\n",
    "\n",
    "ID3算法虽然提出了新思路，但是还是有很多值得改进的地方。　　\n",
    "\n",
    "1. ID3没有考虑连续特征，比如长度，密度都是连续值，无法在ID3运用。这大大限制了ID3的用途。\n",
    "\n",
    "2. ID3采用信息增益大的特征优先建立决策树的节点。很快就被人发现，在相同条件下，取值比较多的特征比取值少的特征信息增益大。比如一个变量有2个值，各为1/2，另一个变量为3个值，各为1/3，其实他们都是完全不确定的变量，但是取3个值的比取2个值的信息增益大。如果校正这个问题呢？\n",
    "\n",
    "3. ID3算法对于缺失值的情况没有做考虑\n",
    "\n",
    "4. 没有考虑过拟合的问题\n",
    "\n",
    "　　　　ID3 算法的作者昆兰基于上述不足，对ID3算法做了改进，这就是C4.5算法，也许你会问，为什么不叫ID4，ID5之类的名字呢?那是因为决策树太火爆，他的ID3一出来，别人二次创新，很快 就占了ID4， ID5，所以他另辟蹊径，取名C4.0算法，后来的进化版为C4.5算法。下面我们就来聊下C4.5算法\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.dataset import load_watermelon_2\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def ent(y: np.array) -> float:\n",
    "    \"\"\"获取样本集的信息熵\n",
    "\n",
    "    Args:\n",
    "        y (np.array): [标签集合]\n",
    "\n",
    "    Returns:\n",
    "        float: [信息熵]\n",
    "    \"\"\"\n",
    "    target_counter = Counter(y)\n",
    "    target_number = y.shape[0]\n",
    "\n",
    "    ent_value = 0\n",
    "    for _, key in enumerate(target_counter.keys()):\n",
    "        _ent = -1 * (target_counter[key] / target_number) * (np.log2(target_counter[key] / target_number))\n",
    "        ent_value +=_ent\n",
    "    return ent_value\n",
    "\n",
    "\n",
    "def gain(d_number: int, d_ent: float, df: pd.DataFrame, a: str) -> float:\n",
    "    \"\"\"获取信息增益\n",
    "\n",
    "    Args:\n",
    "        d_number (int): [整体样本数量]\n",
    "        d_ent (float): [整体样本的信息熵]\n",
    "        df (pd.DataFrame): [结点样本]]\n",
    "        a (str): [划分属性a]\n",
    "\n",
    "    Returns:\n",
    "        float: [节点样本 对应 a属性划分的信息增益]\n",
    "    \"\"\"\n",
    "    a_unique_values = df[a].unique()\n",
    "\n",
    "    dv_ent_value = 0\n",
    "    for a_value in a_unique_values:\n",
    "        v_df = df.loc[df[a]==a_value]\n",
    "        weight = v_df.shape[0] / d_number\n",
    "        dv_ent = weight * ent(v_df['target'])\n",
    "        dv_ent_value += dv_ent\n",
    "    \n",
    "    # gain\n",
    "    return d_ent - dv_ent_value\n",
    "\n",
    "# ------------------------------------------------------\n",
    "\n",
    "\n",
    "class ID3(object):\n",
    "    def __init__(self, df) -> None:\n",
    "        self.df = df\n",
    "        self.shape = df.shape\n",
    "        self.tree = list()\n",
    "        self.d_ent = ent(self.df['target'])\n",
    "        super().__init__()\n",
    "    \n",
    "    def separate(self, df, parent='root'):\n",
    "        \"\"\"进行划分\n",
    "\n",
    "        Args:\n",
    "            df ([type]): [节点样本]\n",
    "            parent (str, optional): [该节点对应的父节点名称]. Defaults to 'root'.\n",
    "\n",
    "        Returns:\n",
    "            [type]: [若无数据或数据只有一个target值时，返回1]\n",
    "        \"\"\"\n",
    "        X_df = df.loc[:, ['色泽', '根蒂', '敲声', '纹理', '脐部', '触感']]\n",
    "        y = df['target']\n",
    "\n",
    "        if X_df.shape[0] == 0:\n",
    "            # 若无数据输入\n",
    "            return 1\n",
    "        elif y.nunique() == 1:\n",
    "            # 若多类型\n",
    "            return 1\n",
    "\n",
    "        max_gain = 0\n",
    "        res_dict = {}\n",
    "        for _, col in enumerate(X_df.columns):  # 对每个属性进行划分\n",
    "            gain_a = gain(\n",
    "                self.shape[0], self.d_ent, df, col\n",
    "            )\n",
    "            if gain_a > max_gain:\n",
    "                max_gain = gain_a\n",
    "                res_dict['gain'] = gain_a\n",
    "                res_dict['a'] = col\n",
    "                res_dict['parent'] = parent\n",
    "        \n",
    "        # 继续划分\n",
    "        a_unique_values = df[res_dict['a']].unique()\n",
    "        for a_value in a_unique_values:\n",
    "            v_df = df.loc[df[res_dict['a']]==a_value]\n",
    "            res_dict['data'] = list(v_df.index)\n",
    "            res_dict['a_v'] = res_dict['a'] + '-' + a_value\n",
    "\n",
    "            # update self.tree\n",
    "            rv = self.separate(v_df, parent=res_dict['a'] + '-' + a_value)\n",
    "            if rv == 1:\n",
    "                self.tree.append({'a': res_dict['a'], 'parent': res_dict['parent'], 'counter': dict(Counter(v_df['target']))})\n",
    "    \n",
    "    def run(self, ):\n",
    "        \"\"\"ID3划分选择\n",
    "\n",
    "        Returns:\n",
    "            [list]: [划分的顺序关系]\n",
    "        \"\"\"\n",
    "        self.separate(self.df)\n",
    "        return self.tree\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "watermelon_df = load_watermelon_2()\n",
    "X = watermelon_df.loc[:, ['色泽', '根蒂', '敲声', '纹理', '脐部', '触感']]\n",
    "y = watermelon_df['target']\n",
    "\n",
    "separation_res = ID3(watermelon_df).run()\n",
    "print(\"划分规则 连接关系 -----> \")\n",
    "print(separation_res)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "划分规则 连接关系 -----> \n",
      "[{'a': '根蒂', 'parent': '纹理-清晰', 'counter': {1: 5}}, {'a': '色泽', 'parent': '根蒂-稍蜷', 'counter': {1: 1}}, {'a': '触感', 'parent': '色泽-乌黑', 'counter': {1: 1}}, {'a': '触感', 'parent': '色泽-乌黑', 'counter': {0: 1}}, {'a': '根蒂', 'parent': '纹理-清晰', 'counter': {0: 1}}, {'a': '触感', 'parent': '纹理-稍糊', 'counter': {1: 1}}, {'a': '触感', 'parent': '纹理-稍糊', 'counter': {0: 4}}, {'a': '纹理', 'parent': 'root', 'counter': {0: 3}}]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aeb5eacbad3f6a7bf06622eeabf3f36373364ed328d2c6589768d7c07331d341"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}