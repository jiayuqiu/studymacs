{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CART 决策树"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 一、简介\n",
    "\n",
    "CART(Classification & Regression)的简称，分类和回顾任务都可以应用。CART决策树用 `基尼指数` 进行划分选择。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 二、基尼指数\n",
    "\n",
    "### 2.1 定义\n",
    "\n",
    "假设：样本D，样本纯度的基尼指数为：\n",
    "\n",
    "$$ Gini(D) = \\sum_{k=1}^{K} \\sum_{k^{'}\\neq k}p_{k}p_{k^{'}} = \\sum_{k=1}^{K} p_{k}(1 - p_{k}) = \\sum_{k=1}^{K}p_{k} - \\sum_{k=1}^{K}p_{k}^{2} = 1 - \\sum_{k=1}^{K}p_{k}^{2} $$\n",
    "\n",
    "直观上理解基尼指数，可以认为，随意从数据D中抽取两个样本，起标记不一致的概率。因此，基尼指数越小，则说明数据集纯度越高(样本中可分类的数据越少)。\n",
    "\n",
    "根据上面的公式，属性 $ a $ 的基尼指数为：\n",
    "\n",
    "$$ Gini\\_index(D, a) = \\sum_{v=1}^{V} \\frac{|D^{v}|}{|D|}Gini(D^{v}) $$\n",
    "\n",
    "综上，我们在候选属性集合 $A$ 中，选择那个使得划分后基尼指数最小的属性作为最优划分属性，即 $ a_{*} = \\mathop{\\arg\\min}_{a\\in A} Gini\\_index(D, a). $"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 三、剪枝处理\n",
    "\n",
    "剪枝是避免过拟合的主要手段，剪枝的基本策略有'预剪枝'与'后剪枝'。\n",
    "\n",
    "- 预剪枝：在决策树生成过程中，对每个结点在划分前进行估计，若当前节点的划分不能带来决策树泛化性能提升，则停止划分并将当前节点标记为叶结点。\n",
    "\n",
    "- 后剪枝：先从训练集中，生成一棵完整的决策树，然后自底向上对非叶节点进行考察，若该节点的子树替换为叶结点能提升泛化性能，则将该子树替换为叶结点。\n",
    "\n",
    "![西瓜数据](../imgs/西瓜数据集2.png)\n",
    "\n",
    "取出1/3作为训练集，2/3作为验证集。利用训练集，训练模型。\n",
    "\n",
    "### 3.1 预剪枝\n",
    "\n",
    "以ID3中的信息增益指标为例，若在划分之前所有样本集中在根节点。以西瓜数据为例，若不进行划分以根节点作为第一个分类，所有样本被交集为'好瓜'。那么，正确率为3/7 * 100% = 42.9%\n",
    "\n",
    "![预剪枝](../imgs/预剪枝.png)\n",
    "\n",
    "在用属性'脐部'划分之后，结点2、3、4标记为 好瓜、好瓜、坏瓜，准确率为 5/7 * 100% = 71.4% > 42.9%，用'脐部'划分得以确定。\n",
    "\n",
    "然后，一次对2、3、4结点进行递归处理，直至划分后的准确率低于划分前，停止划分。\n",
    "\n",
    "预剪枝优缺点\n",
    "\n",
    "- 优点：效率高\n",
    "- 缺点：容易欠拟合\n",
    "\n",
    "### 3.2 后剪枝\n",
    "\n",
    "后剪枝先用训练集生成一棵完整的决策树，如图4.5，决策树准确率为42.9%。\n",
    "\n",
    "后剪枝先考察图4.5中的，6结点。若将6结点划分，进行剪枝，相当于直接把6替换替换为叶结点，样本编号为{7, 15}，一好一坏，约定标记为好。此时，剪枝后，准确率为57.1%。确定进行剪枝。\n",
    "\n",
    "然后，考察结点5，剪枝后准确率还是57.1%不变，可以不进行剪枝。\n",
    "\n",
    "最后得到图4.7。\n",
    "\n",
    "### 3.3 总结\n",
    "\n",
    "对比图4.7与图4.6可看出\n",
    "\n",
    "- 后剪枝决策树通常比预剪枝决策树保留更多的分支。一般情况下，后剪枝决策树的欠拟合风险小，泛化性能往往优于预剪枝决策树。\n",
    "- 后剪枝的效率比预剪枝要慢。\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 四、缺失与连续值处理\n",
    "\n",
    "### 4.1 连续值处理\n",
    "\n",
    "连续属性的可取值不再是有限集合。因此，不能直接根据连续属性的可取值来对结点进行划分。此时，通过连续属性离散化方法来处理。最简单的策略是采用二分法对连续属性进行处理。\n",
    "\n",
    "给定样本$D$和连续属性$a$，假设$a$在$D$上出现了n个不同的取值，将这些至进行升序排列，记作$ \\{ a^{1}, a^{2}, ..., a^{n} \\} $ 。基于划分点t可以将D划分为子集 $ D_{t}^{-} $ 和 $ D_{t}^{+} $。其中$ D_{t}^{-} $为在a上取值小于t的样本，$ D_{t}^{+} $为取值大于t的样本。对于相邻的属性取值$a^{i}$与$a^{i+1}$来说，t在区间$[a^{i}, a^{i+1})$中任意取值所产生的划分结果相同。因此，对于连续属性a，我们可考察包含$n - 1$个元素的候选划分点集合，划分为：\n",
    "\n",
    "$$ T_{a} = \\{ \\frac{a^{i} + a^{i+1} + 1}{2} | 1 \\leqslant i \\leqslant n - 1 \\} $$\n",
    "\n",
    "就是以$a^{i}$与$a^{i+1}$的平均值，作为划分点。然后，就可以像离散属性一样来处理连续属性。\n",
    "\n",
    "以ID3为例，信息增益Gain进行改造可得：\n",
    "\n",
    "$$ \n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "Gain(D, a) &= \\mathop{\\max}_{t \\in T_{a}} Gain(D, a, t) \\\\\n",
    "&= \\mathop{\\max}_{t \\in T_{a}} D - \\sum_{\\lambda \\in \\{-, + \\}}Ent(D_{t}^{\\lambda})\n",
    "\\end{aligned}\n",
    "\\end{equation} \n",
    "$$\n",
    "\n",
    "找出$T_{a}$中，可以让信息增益最大的划分点，用于划分。\n",
    "\n",
    "注意：\n",
    "1. 与离散属性不同，若当前结点划分属性为连续属性，该属性还可作为其后代结点的划分属性。例：父结点上应用 密度 <= 0.381，不会禁止在子结点上使用 密度 <= 0.291。\n",
    "\n",
    "### 4.2 缺失值处理\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;需要解决的问题：\n",
    "1. 在属性值缺失的情况下如何进行划分属性选择？\n",
    "2. 给定划分属性，若样本在该属性上的数据缺失，应该如何进行划分？\n",
    "\n",
    "#### 4.2.1 问题1\n",
    "\n",
    "假设：在属性$a$上，对样本$D$做划分。先找到属性$a$上无缺失的样本$\\widetilde{D}$。此时，仅可以对$\\widetilde{D}$来判断属性$a$的信息增益或基尼系数。\n",
    "\n",
    "在开始学习阶段，初始化每个样本的权重为1. 若属性$a$有$V$个可取值 $\\{a^{1}, ..., a^{v} \\}$，样本的权重为$ \\omega _{x} $. \n",
    "\n",
    "定义：\n",
    "\n",
    "$$ \\rho = \\frac{\\mathop{\\sum}_{x \\in \\widetilde{D}}\\omega_{x}}{\\mathop{\\sum}_{x \\in D}\\omega_{x}} $$\n",
    "\n",
    "$$ \\widetilde{p}_{k} = \\frac{\\mathop{\\sum}_{x \\in \\widetilde{D}_{k}}\\omega_{x}}{\\mathop{\\sum}_{x \\in D}\\omega_{x}}, k \\in [1, |y|] $$\n",
    "\n",
    "$$ \\widetilde{r}_{k} = \\frac{\\mathop{\\sum}_{x \\in \\widetilde{D}^{v}}\\omega_{x}}{\\mathop{\\sum}_{x \\in D}\\omega_{x}}, v \\in [1, V] $$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;其中, 对于属性$a$, $\\rho$ 表示 无缺失值样本所占比例，$ \\widetilde{p}_{k} $表示无缺失样本中第$k$类所占比例，$ \\widetilde{r}_{k} $ 表示无缺失值样本在属性$a$上取值为$a^{v}$的样本所占比例。\n",
    "\n",
    "信息增益的计算方法推广为：\n",
    "\n",
    "$$ \n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "Gain(D, a) &= \\rho \\times Gain(\\widetilde{D}, a) \\\\\n",
    "&= \\rho \\times (Ent(\\widetilde{D}) - \\sum_{v=1}^{V} \\widetilde{r}_{k} Ent(\\widetilde{D}^{v}))\n",
    "\\end{aligned}\n",
    "\\end{equation} \n",
    "$$\n",
    "\n",
    "其中，\n",
    "\n",
    "$$ Ent(\\widetilde{D}) = -\\sum_{k=1}^{K} \\widetilde{p}_{k}\\log_{2} \\widetilde{p}_{k} $$\n",
    "\n",
    "基尼指数的计算方法推广为:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "Gini\\_index(D, a) &= \\rho \\times Gini\\_index(\\widetilde{D}, a) \\\\\n",
    "&= \\rho \\times \\sum_{v=1}^{V} \\widetilde{r_{v}} Gini(\\widetilde{D^{v}})\n",
    "\\end{aligned}\n",
    "\\end{equation} \n",
    "$$\n",
    "\n",
    "其中，\n",
    "\n",
    "$$ Gini(\\widetilde{D}) = 1 - \\sum_{k=1}^{K} p^{2}_{k} $$\n",
    "\n",
    "#### 4.2.2 问题2\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;若样本在划分属性$a$上，取值已知，那么样本的权重保持为 $ \\omega_{x} $；若样本在划分属性$a$上，取值未知，那么将样本x划入所有子节点，且样本权重在属性$a^{v}$对应的子节点上调整为 $\\widetilde{r}_{k} \\cdot \\omega_{x}. $。可以这么理解，就是让在划分属性$a$上，存在缺失值的样本，按不同概率划分到不同的子节点中。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 五、Demo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from utils.dataset import load_watermelon_2_alpha\n",
    "\n",
    "class CART(object):\n",
    "    def __init__(self, ) -> None:\n",
    "        # self.shape = (X.shape[0], X.shape[1] + 1)\n",
    "        self.tree = list()\n",
    "        super().__init__()\n",
    "    \n",
    "    def separate(self, X, y, parent='root'):\n",
    "        min_gini = 9999\n",
    "        res_dict = {}\n",
    "\n",
    "        # if X.shape[0] == 0:\n",
    "        #     # 若无数据输入\n",
    "        #     return 1\n",
    "        # elif y.nunique() == 1:\n",
    "        #     # 若多类型\n",
    "        #     return 1\n",
    "\n",
    "        for _, col in enumerate(X.columns):  # 对每个属性进行划分\n",
    "            gini_index_a = gini_index(\n",
    "                X, y, col\n",
    "            )\n",
    "            if gini_index_a < min_gini:\n",
    "                min_gini = gini_index_a\n",
    "                res_dict['gini'] = gini_index_a\n",
    "                res_dict['a'] = col\n",
    "                res_dict['parent'] = parent\n",
    "                # print(res_dict)\n",
    "        \n",
    "        # 继续划分\n",
    "        a_unique_values = df[res_dict['a']].unique()\n",
    "        for a_value in a_unique_values:\n",
    "            v_df = df.loc[df[res_dict['a']]==a_value]\n",
    "            res_dict['data'] = list(v_df.index)\n",
    "            res_dict['a_v'] = res_dict['a'] + '-' + a_value\n",
    "            print(res_dict)\n",
    "\n",
    "            # update self.tree\n",
    "            rv = self.separate(\n",
    "                X=v_df.loc[:, [x for x in list(v_df.columns) if x != 'target']], \n",
    "                y=v_df['target'], \n",
    "                parent=res_dict['a'] + '-' + a_value\n",
    "            )\n",
    "            if rv == 1:\n",
    "                self.tree.append({'a': res_dict['a'], 'parent': res_dict['parent'], 'counter': dict(Counter(v_df['target']))})\n",
    "    \n",
    "    def fit(self, X, y, prune='pre'):\n",
    "        \"\"\"\n",
    "        拟合CART\n",
    "        \"\"\"\n",
    "        self.separate(X, y)\n",
    "\n",
    "\n",
    "def gini(y) -> float:\n",
    "    \"\"\"基尼指数，计算样本纯度\n",
    "\n",
    "    基尼指数越小，则说明数据集纯度越高(样本中可分类的数据越少)。\n",
    "\n",
    "    Args:\n",
    "        y : [样本标签]\n",
    "\n",
    "    Returns:\n",
    "        float: [样本纯度对应的基尼指数]]\n",
    "    \"\"\"\n",
    "    target_counter_dict = dict(Counter(y))\n",
    "    target_size = len(y)\n",
    "\n",
    "    pk_square_sum = 0\n",
    "    for target_value in target_counter_dict.keys():\n",
    "        pk = target_counter_dict[target_value] / target_size\n",
    "        pk_square_sum += (pk ** 2)\n",
    "    gini = 1 - pk_square_sum\n",
    "    return gini\n",
    "\n",
    "def gini_index(X, y, flag: str) -> float:\n",
    "    \"\"\"对属性a的基尼指数\n",
    "\n",
    "    Args:\n",
    "        X ([type]): [特征]\n",
    "        y ([type]): [标签]\n",
    "        flag (str): [属性a对应的列名]\n",
    "\n",
    "    Returns:\n",
    "        float: [属性a的基尼指数]\n",
    "    \"\"\"\n",
    "    d_size = X.shape[0]  # 样本数量\n",
    "    Av = list(set((X[flag])))  # 在属性a上，a对应的取值列表\n",
    "    Av_size = len(Av)  # 在属性a上，a对应的取值数量\n",
    "    Av_counter_dict = dict(Counter(X[flag]))  # 对Av进行统计\n",
    "\n",
    "    gini_value = 0\n",
    "    for _, av in enumerate(Av):  # 统计属性a上，每个取值对应的gini指数\n",
    "        per = Av_counter_dict[av] / d_size\n",
    "        av_index = np.where(X[flag]==av)[0]  # 样本 在属性a上 取值 为 av 的样本索引\n",
    "\n",
    "        X_dv = X.loc[av_index, :]\n",
    "        y_dv = y.loc[av_index]\n",
    "\n",
    "        # 对缺失值进行处理，测试数据中，av = 0，则为缺失。\n",
    "        # 将该样本按权重放入所有分支中\n",
    "        \n",
    "\n",
    "        dv_gini = gini(y_dv)\n",
    "        gini_value += (per * dv_gini)\n",
    "    return gini_value\n",
    "\n",
    "\n",
    "def pre_prune_fit():\n",
    "    pass\n",
    "\n",
    "def after_prune_fit():\n",
    "    pass\n",
    "\n",
    "\n",
    "df = load_watermelon_2_alpha()\n",
    "df.fillna(0, inplace=True)\n",
    "X = df.loc[:, [x for x in list(df.columns) if x != 'target']]\n",
    "y = df.target\n",
    "print(df)\n",
    "\n",
    "CART().fit(X, y)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    色泽  根蒂  敲声  纹理  脐部  触感  target\n",
      "0    0  蜷缩  浊响  清晰  凹陷  硬滑       1\n",
      "1   乌黑  蜷缩  沉闷  清晰  凹陷   0       1\n",
      "2   乌黑  蜷缩   0  清晰  凹陷  硬滑       1\n",
      "3   青绿  蜷缩  沉闷  清晰  凹陷  硬滑       1\n",
      "4    0  蜷缩  浊响  清晰  凹陷  硬滑       1\n",
      "5   青绿  稍蜷  浊响  清晰   0  软粘       1\n",
      "6   乌黑  稍蜷  浊响  稍糊  稍凹  软粘       1\n",
      "7   乌黑  稍蜷  浊响   0  稍凹  硬滑       1\n",
      "8   乌黑   0  沉闷  稍糊  稍凹  硬滑       0\n",
      "9   青绿  硬挺  清脆  清晰  平坦  软粘       0\n",
      "10  浅白  硬挺  清脆  模糊  平坦   0       0\n",
      "11  浅白  蜷缩   0  模糊  平坦  软粘       0\n",
      "12   0  稍蜷  浊响  稍糊  凹陷  硬滑       0\n",
      "13  浅白  稍蜷  沉闷  稍糊  凹陷  硬滑       0\n",
      "14  乌黑  稍蜷  浊响   0   0  软粘       0\n",
      "15  浅白  蜷缩  浊响  模糊  平坦  硬滑       0\n",
      "16  青绿   0  沉闷  稍糊  稍凹  硬滑       0\n",
      "{'gini': 0.253781512605042, 'a': '纹理', 'parent': 'root', 'data': [0, 1, 2, 3, 4, 5, 9], 'a_v': '纹理-清晰'}\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: Int64Index([6], dtype='int64'). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c9f3e1a865dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m \u001b[0mCART\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-c9f3e1a865dd>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, prune)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0m拟合CART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \"\"\"\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseparate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-c9f3e1a865dd>\u001b[0m in \u001b[0;36mseparate\u001b[0;34m(self, X, y, parent)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# update self.tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             rv = self.separate(\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-c9f3e1a865dd>\u001b[0m in \u001b[0;36mseparate\u001b[0;34m(self, X, y, parent)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 对每个属性进行划分\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             gini_index_a = gini_index(\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             )\n",
      "\u001b[0;32m<ipython-input-10-c9f3e1a865dd>\u001b[0m in \u001b[0;36mgini_index\u001b[0;34m(X, y, flag)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mav_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mflag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mav\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# 样本 在属性a上 取值 为 av 的样本索引\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mX_dv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mav_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0my_dv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mav_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    887\u001b[0m                     \u001b[0;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multi_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple_same_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    773\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    776\u001b[0m             \u001b[0;31m# We should never have retval.ndim < self.ndim, as that should\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m#  be handled by the _getitem_lowerdim call above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1111\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1055\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"display.max_seq_items\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"display.width\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m                 raise KeyError(\n\u001b[0m\u001b[1;32m   1322\u001b[0m                     \u001b[0;34m\"Passing list-likes to .loc or [] with any missing labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m                     \u001b[0;34m\"is no longer supported. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: Int64Index([6], dtype='int64'). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\""
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aeb5eacbad3f6a7bf06622eeabf3f36373364ed328d2c6589768d7c07331d341"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}